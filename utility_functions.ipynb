{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/behnam/relation_extraction/re_behnam/parameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mDATA_SET\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"mothering\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mothering\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#read the input sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_data' is not defined"
     ]
    }
   ],
   "source": [
    "#from collections import Counter\n",
    "from collections import Counter\n",
    "\n",
    "def read_data(file_input,dataset=\"twitter\",delim=\",\"):\n",
    "    if dataset == \"twitter\":      \n",
    "        ff = open(file_input)\n",
    "        h = ff.readline()\n",
    "        header_orig = h.split(delim)\n",
    "        df = pd.read_csv(file_input,delimiter=delim, header=0)#names=header_orig)\n",
    "        #print df.tweet_id[0:10]\n",
    "        df['tweet_posted_time'] = df['tweet_posted_time'].apply(lambda x: datetime.strptime(x.split('.')[0], \\\n",
    "                                                                                            '%Y-%m-%dT%H:%M:%S'))\n",
    "        selected_columns = ['tweet_posted_time', 'tweet_text', 'main_tweet', 'ollie_conf', \\\n",
    "                'ollie_arg1', 'ollie_rel', 'ollie_arg2', 'clean_tweet_polarity','clean_tweet_subjectivity']\n",
    "        df_selected = df[[i for i in df.columns if i in selected_columns]]\n",
    "        #print \"df_selected values - 1\"\n",
    "        #df_selected.values_counts()\n",
    "        #print len(df_selected.index)\n",
    "        df_selected = df_selected.dropna(how = 'any')\n",
    "        print \"Number of instances: \"    \n",
    "        print len(df_selected.index)\n",
    "        #print \" selected dataframe - index 0 : \", df_selected.iloc[0]\n",
    "        return df_selected\n",
    "    if dataset == \"mothering\": \n",
    "        ff = open(file_input)\n",
    "        delim='\\n'\n",
    "        df = pd.read_csv(file_input,delimiter=delim,header=0,error_bad_lines=False)        \n",
    "        return df\n",
    "\n",
    "def save_pairwise_rels(file_loc,g,print_option=True):\n",
    "    f = open(file_loc,'w')\n",
    "    nodes = g.nodes()\n",
    "    for n1 in nodes:\n",
    "        for n2 in nodes:\n",
    "            if n1 is not n2:\n",
    "                l = g.get_edge_data(n1,n2)\n",
    "                if l:\n",
    "                    line = str(n1) + \"\\t\" + str(n2) + \"\\t\" + str(l) + \"\\n\"\n",
    "                    f.write(line)\n",
    "                    if print_option:\n",
    "                        print n1,n2,l    \n",
    "    f.close()\n",
    "def plot_argument_graph(g):\n",
    "    A = nx.nx_agraph.to_agraph(g)\n",
    "    A.layout('dot', args='-Nfontsize=10 -Nwidth=\".2\" -Nheight=\".2\" -Nmargin=0 -Gfontsize=8')\n",
    "    d = draw(g, show='ipynb')\n",
    "    display(d)    \n",
    "    \n",
    "def plot_dep(g,title):\n",
    "    '''\n",
    "    This function takes a DIRECTED graph as input, and plot it inline in Ipython.\n",
    "    '''\n",
    "    #set figure size\n",
    "    '''\n",
    "    plt.figure(figsize=(14,8))\n",
    "    #set style of the graph\n",
    "    pos = graphviz_layout(g,prog='dot')\n",
    "\n",
    "    # \n",
    "    node_labels = nx.get_node_attributes(g, \"id\")\n",
    "    nx.draw_networkx_labels(g, pos, labels = node_labels, font_size=11)\n",
    "    edge_labels_tupels = nx.get_edge_attributes(g, \"rel\")\n",
    "    #print edge_labels_tupels\n",
    "    #edge_labels = [(e[0][0],e[0][1],e[1].value()) for e in edge_labels_tupels]\n",
    "    edge_labels = edge_labels_tupels\n",
    "    #edge_labels = edge_labels_dict.values()\n",
    "    #print edge_labels\n",
    "    nx.draw_networkx_edge_labels(g, pos, labels = edge_labels)\n",
    "    nx.draw_networkx(g,pos=pos,  arrows=True, with_labels=False, node_size=1500, alpha=0.3, node_shape = 's') \n",
    "    \n",
    "    #nx.nx_pylab.  \n",
    "    plt.title(title)\n",
    "    plt.savefig('Dep_tree.png')\n",
    "    plt.show()\n",
    "    '''\n",
    "    A = nx.nx_agraph.to_agraph(g)\n",
    "    A.layout('dot', args='-Nfontsize=10 -Nwidth=\".2\" -Nheight=\".2\" -Nmargin=0 -Gfontsize=8')\n",
    "    A.draw('test.png')\n",
    "    \n",
    "    d = draw(g, show='ipynb')\n",
    "    display(d)\n",
    "    \n",
    "def print_relations(rels):\n",
    "    if len(rels) < 1:\n",
    "        print \"No extraction.\"\n",
    "        return\n",
    "    for ind,r in enumerate(rels):\n",
    "        print \">Extraction Number: \",ind+1, \" - \", \"Pattern: \", r[\"type\"],\" - relation : (\", r[\"arg1\"], \", \", r[\"rel\"], \", \", r[\"arg2\"] ,\")\"\n",
    "    print \" -------------------------------- \\n\"\n",
    "\n",
    "def get_rels_str(rels):\n",
    "    if len(rels) < 1:\n",
    "        return []\n",
    "    rels_str = []\n",
    "    for r in rels:\n",
    "        r_str = \"( \" + r[\"arg1\"] + \", \" + r[\"rel\"] + \", \" + r[\"arg2\"] + \" )\"\n",
    "        rels_str.append(r_str)\n",
    "    return rels_str\n",
    "    \n",
    "def saveToFile_rows(outputLoc, inputList, delim):\n",
    "    with open(outputLoc,\"wb\") as f:\n",
    "        writer = csv.writer(f,delimiter=delim)\n",
    "        writer.writerows(inputList)   \n",
    "        \n",
    "def print_top_relations(all_rels,top_num=-1):\n",
    "    cnt = Counter()\n",
    "    for r in all_rels:\n",
    "        cnt[r] += 1\n",
    "    if top_num == -1: # means print all\n",
    "        print \"Frequent relations:\"\n",
    "        for letter,count in cnt.most_common():\n",
    "            print letter, \": \", count\n",
    "    else:\n",
    "        print \"top \", top_num, \" frequent relations:\"\n",
    "        for letter,count in cnt.most_common(top_num):\n",
    "            print letter, \": \", count     \n",
    "            \n",
    "def error_msg(error_type):\n",
    "    if error_type == \"tokenizer\":\n",
    "        return \"Tokenizer failed during parsing, Ex. there might be a dash in the sentence!\"\n",
    "    \n",
    "    \n",
    "def get_entity_versions(dataset=DATA_SET):\n",
    "    entity_versions = defaultdict(list)\n",
    "    if dataset==\"mothering\":\n",
    "        entity_versions['parents'] = ['parents', 'parent', 'i', 'we' , 'us', 'you']\n",
    "        entity_versions['children'] = ['child', 'kid', 'kids', 'children', 'daughter', 'daughters',\n",
    "                                       'son', 'sons', 'toddler',\n",
    "                                       'toddlers', 'kiddo', 'boy','dd','ds']\n",
    "        entity_versions['medical prof'] = ['doctor', 'doctors', 'pediatrician', \n",
    "                                           'pediatricians', 'nurse', 'nurses', 'ped', 'md', 'dr']\n",
    "        entity_versions['government'] = ['government', 'cdc', 'federal', 'feds',\n",
    "                                         'center for disease control', 'officials',\n",
    "                                         'politician', 'official', 'law']\n",
    "        entity_versions['religous inst'] = ['faith', 'religion', 'pastor', 'pastors',\n",
    "                                            'parish', 'parishes', 'church', 'churches',\n",
    "                                            'congregation', 'congregations', 'clergy']\n",
    "        entity_versions['schools'] = ['teacher', 'teachers', 'preschools', 'preschool', \n",
    "                                      'school', 'schools', 'class', \n",
    "                                      'daycare', 'daycares', 'classes']\n",
    "        entity_versions['vaccines'] = ['vaccines', 'vax', 'vaccine', 'vaccination', \n",
    "                                       'vaccinations', 'shots', 'shot', 'vaxed',\n",
    "                                       'unvax', 'unvaxed', 'nonvaxed', 'vaccinate',\n",
    "                                       'vaccinated', 'vaxes', 'vaxing', 'vaccinating',\n",
    "                                       'substances', 'ingredients']\n",
    "        entity_versions['exemptions'] = ['exemption', 'exempt']\n",
    "        entity_versions['VPDs'] = ['varicella', 'chickenpox', \n",
    "                                   'flu', 'whooping cough', 'tetanus', 'pertussis', \n",
    "                                   'hepatitis', 'polio', 'mumps', 'measles', 'diphtheria']\n",
    "        entity_versions['adverse effects'] = ['autism', 'autistic', 'fever', 'fevers',\n",
    "                                              'reaction', 'reactions', 'infection', 'infections', 'inflammation', 'inflammations',\n",
    "                                              'pain', 'pains', 'bleeding', 'bruising', 'diarrhea', 'diarrhoea']\n",
    "\n",
    "    return entity_versions\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var add_edit_shortcuts = {\n",
    "    'shift-enter' : {\n",
    "                help : 'run cell, select next codecell',\n",
    "                help_index : 'bb',\n",
    "                handler : function (event) {\n",
    "                IPython.notebook.execute_cell_and_select_below();\n",
    "                // find next CodeCell and go into edit mode if possible, else stay in next cell\n",
    "                var i;\n",
    "                for (i = IPython.notebook.get_selected_index(); i < IPython.notebook.ncells() ;i++) {\n",
    "                var cell = IPython.notebook.get_cell(i);\n",
    "                if (cell instanceof IPython.CodeCell) {\n",
    "                    IPython.notebook.select(i);\n",
    "                    IPython.notebook.edit_mode();\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            return false;\n",
    "        }\n",
    "    },\n",
    "};\n",
    "\n",
    "IPython.keyboard_manager.edit_shortcuts.add_shortcuts(add_edit_shortcuts); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
