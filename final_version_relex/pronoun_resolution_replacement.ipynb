{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "data_dir = \"../../data/GoodReads/\"\n",
    "input_file = \"../../data/GoodReads/The Hobbit (Middle-Earth Universe)_raw_en.txt\"\n",
    "output_file = \"../../data/GoodReads/The Hobbit (Middle-Earth Universe)_raw_en_with_pronouns.csv\"\n",
    "print os.getcwd()\n",
    "\n",
    "df = pd.read_csv(input_file, delimiter='\\n', header=0, error_bad_lines=False)  \n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Pusheen and Smitha walked along the beach. Pusheen wanted to surf,'\n",
    "    'but fell off the surfboard.')\n",
    "output = nlp.annotate(text, properties={\n",
    "    'annotators': 'tokenize,ssplit,pos,depparse,parse,coref',\n",
    "    'outputFormat': 'json'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'corefs': {u'3': [{u'animacy': u'ANIMATE',\n",
       "    u'endIndex': 4,\n",
       "    u'gender': u'UNKNOWN',\n",
       "    u'headIndex': 1,\n",
       "    u'id': 1,\n",
       "    u'isRepresentativeMention': False,\n",
       "    u'number': u'PLURAL',\n",
       "    u'position': [1, 2],\n",
       "    u'sentNum': 1,\n",
       "    u'startIndex': 1,\n",
       "    u'text': u'Pusheen and Smitha',\n",
       "    u'type': u'LIST'},\n",
       "   {u'animacy': u'ANIMATE',\n",
       "    u'endIndex': 2,\n",
       "    u'gender': u'UNKNOWN',\n",
       "    u'headIndex': 1,\n",
       "    u'id': 3,\n",
       "    u'isRepresentativeMention': True,\n",
       "    u'number': u'SINGULAR',\n",
       "    u'position': [2, 1],\n",
       "    u'sentNum': 2,\n",
       "    u'startIndex': 1,\n",
       "    u'text': u'Pusheen',\n",
       "    u'type': u'PROPER'}]},\n",
       " u'sentences': [{u'basicDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'walked',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'and',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'conj',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'Smitha',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'along',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'nmod',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'beach',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'}],\n",
       "   u'enhancedDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'walked',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'and',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'conj:and',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'Smitha',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'Smitha',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'along',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'nmod:along',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'beach',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'}],\n",
       "   u'enhancedPlusPlusDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'walked',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'and',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'conj:and',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'Smitha',\n",
       "     u'governor': 1,\n",
       "     u'governorGloss': u'Pusheen'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'Smitha',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'along',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'beach'},\n",
       "    {u'dep': u'nmod:along',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'beach',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'walked'}],\n",
       "   u'index': 0,\n",
       "   u'parse': u'(ROOT\\n  (S\\n    (NP (NNP Pusheen)\\n      (CC and)\\n      (NNP Smitha))\\n    (VP (VBD walked)\\n      (PP (IN along)\\n        (NP (DT the) (NN beach))))\\n    (. .)))',\n",
       "   u'tokens': [{u'after': u' ',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 0,\n",
       "     u'characterOffsetEnd': 7,\n",
       "     u'index': 1,\n",
       "     u'lemma': u'Pusheen',\n",
       "     u'ner': u'PERSON',\n",
       "     u'originalText': u'Pusheen',\n",
       "     u'pos': u'NNP',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'Pusheen'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 8,\n",
       "     u'characterOffsetEnd': 11,\n",
       "     u'index': 2,\n",
       "     u'lemma': u'and',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'and',\n",
       "     u'pos': u'CC',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'and'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 12,\n",
       "     u'characterOffsetEnd': 18,\n",
       "     u'index': 3,\n",
       "     u'lemma': u'Smitha',\n",
       "     u'ner': u'PERSON',\n",
       "     u'originalText': u'Smitha',\n",
       "     u'pos': u'NNP',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'Smitha'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 19,\n",
       "     u'characterOffsetEnd': 25,\n",
       "     u'index': 4,\n",
       "     u'lemma': u'walk',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'walked',\n",
       "     u'pos': u'VBD',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'walked'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 26,\n",
       "     u'characterOffsetEnd': 31,\n",
       "     u'index': 5,\n",
       "     u'lemma': u'along',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'along',\n",
       "     u'pos': u'IN',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'along'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 32,\n",
       "     u'characterOffsetEnd': 35,\n",
       "     u'index': 6,\n",
       "     u'lemma': u'the',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'the',\n",
       "     u'pos': u'DT',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'the'},\n",
       "    {u'after': u'',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 36,\n",
       "     u'characterOffsetEnd': 41,\n",
       "     u'index': 7,\n",
       "     u'lemma': u'beach',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'beach',\n",
       "     u'pos': u'NN',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'beach'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 41,\n",
       "     u'characterOffsetEnd': 42,\n",
       "     u'index': 8,\n",
       "     u'lemma': u'.',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'.',\n",
       "     u'pos': u'.',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'.'}]},\n",
       "  {u'basicDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'wanted',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'surf'},\n",
       "    {u'dep': u'nmod',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'surf',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u',',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'but',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'conj',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'fell',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'compound:prt',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'off',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 10,\n",
       "     u'governorGloss': u'surfboard'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 10,\n",
       "     u'dependentGloss': u'surfboard',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 11,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'}],\n",
       "   u'enhancedDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'wanted',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'surf'},\n",
       "    {u'dep': u'nmod:to',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'surf',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u',',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'but',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'conj:but',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'fell',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'compound:prt',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'off',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 10,\n",
       "     u'governorGloss': u'surfboard'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 10,\n",
       "     u'dependentGloss': u'surfboard',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 11,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'}],\n",
       "   u'enhancedPlusPlusDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'wanted',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'Pusheen',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'surf'},\n",
       "    {u'dep': u'nmod:to',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'surf',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u',',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'cc',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'but',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'conj:but',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'fell',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'},\n",
       "    {u'dep': u'compound:prt',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'off',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 10,\n",
       "     u'governorGloss': u'surfboard'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 10,\n",
       "     u'dependentGloss': u'surfboard',\n",
       "     u'governor': 7,\n",
       "     u'governorGloss': u'fell'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 11,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'wanted'}],\n",
       "   u'index': 1,\n",
       "   u'parse': u'(ROOT\\n  (S\\n    (NP (NNP Pusheen))\\n    (VP\\n      (VP (VBD wanted)\\n        (PP (TO to)\\n          (NP (NN surf))))\\n      (, ,)\\n      (CC but)\\n      (VP (VBD fell)\\n        (PRT (RP off))\\n        (NP (DT the) (NN surfboard))))\\n    (. .)))',\n",
       "   u'tokens': [{u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 43,\n",
       "     u'characterOffsetEnd': 50,\n",
       "     u'index': 1,\n",
       "     u'lemma': u'Pusheen',\n",
       "     u'ner': u'PERSON',\n",
       "     u'originalText': u'Pusheen',\n",
       "     u'pos': u'NNP',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'Pusheen'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 51,\n",
       "     u'characterOffsetEnd': 57,\n",
       "     u'index': 2,\n",
       "     u'lemma': u'want',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'wanted',\n",
       "     u'pos': u'VBD',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'wanted'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 58,\n",
       "     u'characterOffsetEnd': 60,\n",
       "     u'index': 3,\n",
       "     u'lemma': u'to',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'to',\n",
       "     u'pos': u'TO',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'to'},\n",
       "    {u'after': u'',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 61,\n",
       "     u'characterOffsetEnd': 65,\n",
       "     u'index': 4,\n",
       "     u'lemma': u'surf',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'surf',\n",
       "     u'pos': u'NN',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'surf'},\n",
       "    {u'after': u'',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 65,\n",
       "     u'characterOffsetEnd': 66,\n",
       "     u'index': 5,\n",
       "     u'lemma': u',',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u',',\n",
       "     u'pos': u',',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u','},\n",
       "    {u'after': u' ',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 66,\n",
       "     u'characterOffsetEnd': 69,\n",
       "     u'index': 6,\n",
       "     u'lemma': u'but',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'but',\n",
       "     u'pos': u'CC',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'but'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 70,\n",
       "     u'characterOffsetEnd': 74,\n",
       "     u'index': 7,\n",
       "     u'lemma': u'fall',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'fell',\n",
       "     u'pos': u'VBD',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'fell'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 75,\n",
       "     u'characterOffsetEnd': 78,\n",
       "     u'index': 8,\n",
       "     u'lemma': u'off',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'off',\n",
       "     u'pos': u'RP',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'off'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 79,\n",
       "     u'characterOffsetEnd': 82,\n",
       "     u'index': 9,\n",
       "     u'lemma': u'the',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'the',\n",
       "     u'pos': u'DT',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'the'},\n",
       "    {u'after': u'',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 83,\n",
       "     u'characterOffsetEnd': 92,\n",
       "     u'index': 10,\n",
       "     u'lemma': u'surfboard',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'surfboard',\n",
       "     u'pos': u'NN',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'surfboard'},\n",
       "    {u'after': u'',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 92,\n",
       "     u'characterOffsetEnd': 93,\n",
       "     u'index': 11,\n",
       "     u'lemma': u'.',\n",
       "     u'ner': u'O',\n",
       "     u'originalText': u'.',\n",
       "     u'pos': u'.',\n",
       "     u'speaker': u'PER0',\n",
       "     u'word': u'.'}]}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (NP (NNP Pusheen)\n",
      "      (CC and)\n",
      "      (NNP Smitha))\n",
      "    (VP (VBD walked)\n",
      "      (PP (IN along)\n",
      "        (NP (DT the) (NN beach))))\n",
      "    (. .)))\n",
      "{u'sentences': [{u'1': {u'text': u'Smitha', u'begin': 2, u'end': 3}, u'0': {u'text': u'Pusheen', u'begin': 0, u'end': 1}, u'length': 2}, {u'0': {u'text': u'Pusheen', u'begin': 0, u'end': 1}, u'length': 1}]}\n",
      "{u'sentences': [{u'0': {u'text': u'walked', u'begin': 3, u'end': 4}, u'length': 1}, {u'1': {u'text': u'fell', u'begin': 6, u'end': 7}, u'0': {u'text': u'wanted', u'begin': 1, u'end': 2}, u'length': 2}]}\n"
     ]
    }
   ],
   "source": [
    "print(output['sentences'][0]['parse'])\n",
    "output = nlp.tokensregex(text, pattern='/Pusheen|Smitha/', filter=False)\n",
    "print(output)\n",
    "output = nlp.semgrex(text, pattern='{tag: VBD}', filter=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycorenlp.corenlp.StanfordCoreNLP instance at 0x10b445e18>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python\n"
     ]
    }
   ],
   "source": [
    "corenlp_python_dir = '/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python/'\n",
    "#sys.path.append('/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python/')\n",
    "#a = '/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python/'\n",
    "\n",
    "os.chdir(corenlp_python_dir)\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#os.system(\"corenlp.py -p 1234\")\\nimport subprocess\\nsubprocess.Popen(\"corenlp.py -p 1234\", shell=True)\\nfrom corenlp import *\\ncorenlp = StanfordCoreNLP()  # wait a few minutes...\\n#corenlp.parse(\"Parse this sentence.\") -> output type :: str \\n#loads(server.parse(sent)) :: output type : dict\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#os.system(\"corenlp.py -p 1234\")\n",
    "import subprocess\n",
    "subprocess.Popen(\"corenlp.py -p 1234\", shell=True)\n",
    "from corenlp import *\n",
    "corenlp = StanfordCoreNLP()  # wait a few minutes...\n",
    "#corenlp.parse(\"Parse this sentence.\") -> output type :: str \n",
    "#loads(server.parse(sent)) :: output type : dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result {u'coref': [[[[u'It', 1, 0, 0, 1], [u'Hello world', 0, 1, 0, 2]]]], u'sentences': [{u'parsetree': u'[Text=world CharacterOffsetBegin=6 CharacterOffsetEnd=11 PartOfSpeech=NN Lemma=world NamedEntityTag=O] [Text=. CharacterOffsetBegin=11 CharacterOffsetEnd=12 PartOfSpeech=. Lemma=. NamedEntityTag=O] (ROOT (S (VP (NP (INTJ (UH Hello)) (NP (NN world)))) (. .)))', u'text': u'Hello world.', u'dependencies': [[u'root', u'ROOT', u'world'], [u'discourse', u'world', u'Hello'], [u'punct', u'world', u'.']], u'words': [[u'Hello', {u'NamedEntityTag': u'O', u'CharacterOffsetEnd': u'5', u'CharacterOffsetBegin': u'0', u'PartOfSpeech': u'UH', u'Lemma': u'hello'}]]}, {u'parsetree': u'[Text=is CharacterOffsetBegin=17 CharacterOffsetEnd=19 PartOfSpeech=VBZ Lemma=be NamedEntityTag=O] [Text=so CharacterOffsetBegin=20 CharacterOffsetEnd=22 PartOfSpeech=RB Lemma=so NamedEntityTag=O] [Text=beautiful CharacterOffsetBegin=23 CharacterOffsetEnd=32 PartOfSpeech=JJ Lemma=beautiful NamedEntityTag=O] (ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (RB so) (JJ beautiful)))))', u'text': u'It is so beautiful', u'dependencies': [[u'root', u'ROOT', u'beautiful'], [u'nsubj', u'beautiful', u'It'], [u'cop', u'beautiful', u'is'], [u'advmod', u'beautiful', u'so']], u'words': [[u'It', {u'NamedEntityTag': u'O', u'CharacterOffsetEnd': u'16', u'CharacterOffsetBegin': u'14', u'PartOfSpeech': u'PRP', u'Lemma': u'it'}]]}]}\n"
     ]
    }
   ],
   "source": [
    "import jsonrpc\n",
    "from simplejson import loads\n",
    "server = jsonrpc.ServerProxy(jsonrpc.JsonRpc20(),\n",
    "                             jsonrpc.TransportTcpIp(addr=(\"127.0.0.1\", 8080)))\n",
    "\n",
    "#sent = \"Some books are almost impossible to review. If a book is bad, how easily can we dwell on its flaws! But if the book is good, how do you give any recommendation that is equal the book? Unless you are an author of equal worth to the one whose work you review, what powers of prose and observation are you likely to have to fitly adorn the work? 'The Hobbit' is at one level simply a charming adventure story, perhaps one of the most charming and most adventurous ever told.\"\n",
    "#sent.replace('\"','')\n",
    "#print sent\n",
    "sent = \"Hello world.  It is so beautiful\"\n",
    "result = loads(server.parse(sent))\n",
    "print \"Result\", result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name batch_parse",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-83612312c9ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcorenlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorenlp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stanford-corenlp-full-2016-10-31/\"\u001b[0m\u001b[0;31m#\"stanford-corenlp-full-2013-06-20/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_text_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sample_raw_text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorenlp_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It returns a generator object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name batch_parse"
     ]
    }
   ],
   "source": [
    "from corenlp import batch_parse\n",
    "corenlp_dir = \"stanford-corenlp-full-2016-10-31/\"#\"stanford-corenlp-full-2013-06-20/\"\n",
    "raw_text_directory = \"sample_raw_text/\"\n",
    "parsed = batch_parse(raw_text_directory, corenlp_dir)  # It returns a generator object\n",
    "print parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Some books are almost impossible to review.\n",
      "If a book is bad, how easily can we dwell on its flaws!\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Some books are almost impossible to review.\n",
      "If a book is bad, how easily can we dwell on its flaws!\n",
      "But if the book is good, how do you give any recommendation that is equal the book?\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "If a book is bad, how easily can we dwell on its flaws!\n",
      "But if the book is good, how do you give any recommendation that is equal the book?\n",
      "Unless you are an author of equal worth to the one whose work you review, what powers of prose and observation are you likely to have to fitly adorn the work?\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "But if the book is good, how do you give any recommendation that is equal the book?\n",
      "Unless you are an author of equal worth to the one whose work you review, what powers of prose and observation are you likely to have to fitly adorn the work?\n",
      "'The Hobbit' is at one level simply a charming adventure story, perhaps one of the most charming and most adventurous ever told.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Unless you are an author of equal worth to the one whose work you review, what powers of prose and observation are you likely to have to fitly adorn the work?\n",
      "'The Hobbit' is at one level simply a charming adventure story, perhaps one of the most charming and most adventurous ever told.\n",
      "There, see how simple that was?\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "'The Hobbit' is at one level simply a charming adventure story, perhaps one of the most charming and most adventurous ever told.\n",
      "There, see how simple that was?\n",
      "If you have not read it, you should, because it is quite enjoyable.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "There, see how simple that was?\n",
      "If you have not read it, you should, because it is quite enjoyable.\n",
      "At some level, there is little more to say.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "If you have not read it, you should, because it is quite enjoyable.\n",
      "At some level, there is little more to say.\n",
      "Enjoy the story as the simple entertainment it was meant to be.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "At some level, there is little more to say.\n",
      "Enjoy the story as the simple entertainment it was meant to be.\n",
      "Read it to your children and luxuriate in the excitement and joy that shines from their faces.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Enjoy the story as the simple entertainment it was meant to be.\n",
      "Read it to your children and luxuriate in the excitement and joy that shines from their faces.\n",
      "That's enough.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Read it to your children and luxuriate in the excitement and joy that shines from their faces.\n",
      "That's enough.\n",
      "But if it was only simple entertainment, I do not think that it would be anything more than just a good book.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "That's enough.\n",
      "But if it was only simple entertainment, I do not think that it would be anything more than just a good book.\n",
      "Instead, this simple children's story resonates and fascinates.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "But if it was only simple entertainment, I do not think that it would be anything more than just a good book.\n",
      "Instead, this simple children's story resonates and fascinates.\n",
      "It teases and hints at something larger and grander, and it instructs and lectures as from one of the most subtle intellects without ever feeling like it is instructing, lecturing or being condescending.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "Instead, this simple children's story resonates and fascinates.\n",
      "It teases and hints at something larger and grander, and it instructs and lectures as from one of the most subtle intellects without ever feeling like it is instructing, lecturing or being condescending.\n",
      "At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in 'The Hobbit' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "It teases and hints at something larger and grander, and it instructs and lectures as from one of the most subtle intellects without ever feeling like it is instructing, lecturing or being condescending.\n",
      "At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in 'The Hobbit' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.\n",
      "How often has that idea fascinated me.\n",
      "ind:  0  --- \n",
      " t_with_context: \n",
      "At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in 'The Hobbit' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.\n",
      "How often has that idea fascinated me.\n",
      "Consider also how the story opens, with Bilbo's breezy unreflective manners which are polite in form but not in spirit, and Gandalf's continual meditation on the meaning of 'Good morning.\n"
     ]
    },
    {
     "ename": "RPCTransportError",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRPCTransportError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-945c4eda2cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0moutput_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_output_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_with_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mdict_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mf_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-945c4eda2cfa>\u001b[0m in \u001b[0;36mget_output_row\u001b[0;34m(t_with_context, t_main, post_number, sentence_number)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_output_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_with_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mres_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_with_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m#res_dict = loads(corenlp.parse(t_with_context))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python/jsonrpc.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__req\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__req\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;31m#=========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/behnam/Desktop/Behnam_Files/vwani_text_mining/RE_Behnam/nlp_tools/stanford-corenlp-python/jsonrpc.pyc\u001b[0m in \u001b[0;36m__req\u001b[0;34m(self, methodname, args, kwargs, id)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mresp_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendrecv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreq_str\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRPCTransportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_serializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads_response\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mresp_str\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRPCTransportError\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from utility_functions import *\n",
    "\n",
    "MAX_ITERATION = 5\n",
    "output_name = \"The Hobbit (Middle-Earth Universe)_raw_en_with_pronouns\"\n",
    "f_output = open(data_dir + output_name + \"_\" + str(MAX_ITERATION) +\".csv\", \"w\")\n",
    "\n",
    "header = ['post_number', 'text_with_context','main_sentence','sentence_number' ,'has_pronoun','pronouns','corenlp_output']\n",
    "dict_writer = csv.DictWriter(f_output, header)\n",
    "dict_writer.writeheader()#writerow(header)\n",
    "\n",
    "'''\n",
    "for ind, t_orig in enumerate(texts):\n",
    "    if MAX_ITERATION >= 0:\n",
    "        if ind > MAX_ITERATION:\n",
    "            break    \n",
    "    print len(t_orig)\n",
    "'''\n",
    "\n",
    "def get_output_row(t_with_context, t_main, post_number, sentence_number):\n",
    "    res_dict = loads(server.parse(t_with_context))\n",
    "    #res_dict = loads(corenlp.parse(t_with_context))\n",
    "    output_row = defaultdict(list)\n",
    "    t_with_context = t_with_context.encode('utf-8')\n",
    "    output_row[\"post_number\"] = post_number\n",
    "    output_row[\"text_with_context\"] = t_with_context\n",
    "    output_row[\"main_sentence\"] = t_main\n",
    "    output_row[\"sentence_number\"] = sentence_number\n",
    "    if \"coref\" in res_dict.keys():\n",
    "        output_row[\"has_pronoun\"] = 1\n",
    "        output_row[\"pronouns\"] = res_dict[\"coref\"]\n",
    "        output_row[\"corenlp_output\"] = res_dict         \n",
    "    else:\n",
    "        output_row[\"has_pronoun\"] = 0\n",
    "        output_row[\"pronouns\"] = \"\"\n",
    "        output_row[\"corenlp_output\"] = \"\"   \n",
    "    return output_row\n",
    "\n",
    "#'''\n",
    "for ind, t_orig in enumerate(texts):\n",
    "    '''\n",
    "    IF SENT_TMP LEN IS GREATER THAN 1023 CHARS, THEN IT CRASHES.\n",
    "    sent_tmp = t_orig[0:10]\n",
    "    for i in range(10,len(t_orig)):\n",
    "        print i\n",
    "        sent_tmp += t_orig[i]\n",
    "        res_dict = loads(server.parse(sent_tmp))\n",
    "    '''\n",
    "    if MAX_ITERATION >= 0:\n",
    "        if ind > MAX_ITERATION:\n",
    "            break\n",
    "    #if ind<=5:\n",
    "    #    continue\n",
    "    #try:\n",
    "    t_orig = clean_sent(t_orig)\n",
    "    t_orig = t_orig.decode('utf-8')\n",
    "    t_sentences = sent_tokenize(t_orig)\n",
    "    total_sentences = len(t_sentences)\n",
    "    #print \"total sentences:\", total_sentences\n",
    "    if total_sentences > 3:\n",
    "        for t_ind in range(total_sentences):\n",
    "            t_sentences[t_ind] = t_sentences[t_ind].encode('utf-8')\n",
    "        for t_ind in range(total_sentences):\n",
    "            #if t_ind != 15:\n",
    "            #    continue\n",
    "            t_with_context = \"\"\n",
    "            if t_ind == 0:\n",
    "                t_with_context = t_sentences[t_ind] + \"\\n\" + t_sentences[t_ind+1]\n",
    "            elif t_ind == total_sentences-1:\n",
    "                t_with_context = t_sentences[t_ind-1] + \"\\n\" + t_sentences[t_ind]\n",
    "            else:\n",
    "                t_with_context = t_sentences[t_ind-1] + \"\\n\" + t_sentences[t_ind] + \"\\n\" + t_sentences[t_ind+1]\n",
    "            print \"ind: \", ind , \" --- \\n t_with_context: \\n\", t_with_context\n",
    "            #output_row = defaultdict(list)\n",
    "            if len(t_with_context) > 1023:\n",
    "                print \"*** LONG SENT post#\", ind, \" : sentence # : \", t_ind ,\" len: \",len(t_with_context), \" \\n\\n\", t_with_context , \" ***\\n\\n\"\n",
    "                continue\n",
    "            #try:\n",
    "            output_row = get_output_row(t_with_context, t_sentences[t_ind], ind, t_ind) \n",
    "            dict_writer.writerow(output_row)\n",
    "            f_output.flush()\n",
    "            #except:\n",
    "            #    print \"*** Error in post #\", ind, \" : sentence # : \", t_ind ,\" len: \",len(t_with_context), \" \\n\\n\", t_with_context , \" ***\\n\\n\"                \n",
    "    else:\n",
    "        try:\n",
    "            output_row = get_output_row(t_with_context, t_sentences[t_ind], ind, t_ind)\n",
    "            dict_writer.writerow(output_row)\n",
    "            f_output.flush()\n",
    "        except:\n",
    "            print \"*** Error in post #\", ind, \" : sentence # : \", t_ind ,\" len: \",len(t_with_context), \" \\n\\n\", t_with_context , \" ***\\n\\n\"                \n",
    "    #except:\n",
    "    #    print \"*** Error in post #\", ind, \" : sentence # : \", t_ind ,\" len: \",len(t_with_context), \" \\n\\n\", t_with_context , \" ***\\n\\n\"\n",
    "        \n",
    "f_output.close()        \n",
    "#'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "sent = \"Do you know what to do in case of payment card fraud? Here the basic steps. Very important: always report it!\"\n",
    "res_dict = corenlp.parse(sent)\n",
    "#res_dict = loads(server.parse(sent))#loads(server.parse(sent))\n",
    "print type(res_dict)\n",
    "#res_dict = ast.literal_eval(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[u'it', 2, 5, 5, 6], [u'case of payment card fraud', 0, 7, 7, 12]]]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[\"coref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coref_pronoun = res_dict[\"coref\"][0][0][0]\n",
    "print coref_pronoun\n",
    "coref_orig = res_dict[\"coref\"][0][0][1]\n",
    "print coref_orig\n",
    "s_pronoun = res_dict[\"sentences\"][coref_pronoun[1]][\"text\"]\n",
    "s_orig = res_dict[\"sentences\"][coref_orig[1]][\"text\"]\n",
    "print s_pronoun\n",
    "print s_orig\n",
    "\n",
    "start_ind_pronoun = coref_pronoun[3]\n",
    "end_ind_pronouon = coref_pronoun[4]\n",
    "s_replaced = s_pronoun[:start_ind_pronoun]\n",
    "sent_tokenize(s_pronoun)\n",
    "print s_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very important: always report it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Very',\n",
       " 'important',\n",
       " ':',\n",
       " 'always',\n",
       " 'report',\n",
       " 'case of payment card fraud',\n",
       " '!']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "print s_pronoun\n",
    "s_pronoun_tokenized = word_tokenize(s_pronoun)\n",
    "s_replaced[5] = coref_orig[0]\n",
    "s_final = \"\"\n",
    "''.join(s_pronoun_tokenized)\n",
    "for i in range(len(s_pronoun_tokenized)):\n",
    "    s_final += s_pronoun_tokenized[i]\n",
    "s_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=\"At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in 'The Hobbit' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.\\\n",
    "How often has that idea fascinated me.\\\n",
    "Consider also how the story opens, with Bilbo's breezy unreflective manners which are polite in form but not in spirit, and Gandalf's continual meditation on the meaning of 'Good morning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coref\": [[[[\"the story\", 0, 1, 70, 72], [\"a story of a good time\", 0, 4, 33, 39]]]], \"sentences\": [{\"parsetree\": \"[Text=its CharacterOffsetBegin=3 CharacterOffsetEnd=6 PartOfSpeech=PRP$ Lemma=its NamedEntityTag=O] [Text=heart CharacterOffsetBegin=7 CharacterOffsetEnd=12 PartOfSpeech=NN Lemma=heart NamedEntityTag=O] [Text=, CharacterOffsetBegin=12 CharacterOffsetEnd=13 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=the CharacterOffsetBegin=14 CharacterOffsetEnd=17 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=complaint CharacterOffsetBegin=18 CharacterOffsetEnd=27 PartOfSpeech=NN Lemma=complaint NamedEntityTag=O] [Text=I CharacterOffsetBegin=28 CharacterOffsetEnd=29 PartOfSpeech=PRP Lemma=I NamedEntityTag=O] [Text=opened CharacterOffsetBegin=30 CharacterOffsetEnd=36 PartOfSpeech=VBD Lemma=open NamedEntityTag=O] [Text=the CharacterOffsetBegin=37 CharacterOffsetEnd=40 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=review CharacterOffsetBegin=41 CharacterOffsetEnd=47 PartOfSpeech=NN Lemma=review NamedEntityTag=O] [Text=with CharacterOffsetBegin=48 CharacterOffsetEnd=52 PartOfSpeech=IN Lemma=with NamedEntityTag=O] [Text=is CharacterOffsetBegin=53 CharacterOffsetEnd=55 PartOfSpeech=VBZ Lemma=be NamedEntityTag=O] [Text=just CharacterOffsetBegin=56 CharacterOffsetEnd=60 PartOfSpeech=RB Lemma=just NamedEntityTag=O] [Text=a CharacterOffsetBegin=61 CharacterOffsetEnd=62 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=variation CharacterOffsetBegin=63 CharacterOffsetEnd=72 PartOfSpeech=NN Lemma=variation NamedEntityTag=O] [Text=on CharacterOffsetBegin=73 CharacterOffsetEnd=75 PartOfSpeech=IN Lemma=on NamedEntityTag=O] [Text=one CharacterOffsetBegin=76 CharacterOffsetEnd=79 PartOfSpeech=CD Lemma=one NamedEntityTag=NUMBER NormalizedNamedEntityTag=1.0] [Text=of CharacterOffsetBegin=80 CharacterOffsetEnd=82 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=the CharacterOffsetBegin=83 CharacterOffsetEnd=86 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=many CharacterOffsetBegin=87 CharacterOffsetEnd=91 PartOfSpeech=JJ Lemma=many NamedEntityTag=O] [Text=nuanced CharacterOffsetBegin=92 CharacterOffsetEnd=99 PartOfSpeech=JJ Lemma=nuanced NamedEntityTag=O] [Text=observations CharacterOffsetBegin=100 CharacterOffsetEnd=112 PartOfSpeech=NNS Lemma=observation NamedEntityTag=O] [Text=Tolkien CharacterOffsetBegin=113 CharacterOffsetEnd=120 PartOfSpeech=NNP Lemma=Tolkien NamedEntityTag=ORGANIZATION] [Text=makes CharacterOffsetBegin=121 CharacterOffsetEnd=126 PartOfSpeech=VBZ Lemma=make NamedEntityTag=O] [Text=in CharacterOffsetBegin=127 CharacterOffsetEnd=129 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=` CharacterOffsetBegin=130 CharacterOffsetEnd=131 PartOfSpeech=`` Lemma=` NamedEntityTag=O] [Text=The CharacterOffsetBegin=131 CharacterOffsetEnd=134 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=Hobbit CharacterOffsetBegin=135 CharacterOffsetEnd=141 PartOfSpeech=NNP Lemma=Hobbit NamedEntityTag=O] [Text=\\' CharacterOffsetBegin=141 CharacterOffsetEnd=142 PartOfSpeech=POS Lemma=\\' NamedEntityTag=O] [Text=when CharacterOffsetBegin=143 CharacterOffsetEnd=147 PartOfSpeech=WRB Lemma=when NamedEntityTag=O] [Text=he CharacterOffsetBegin=148 CharacterOffsetEnd=150 PartOfSpeech=PRP Lemma=he NamedEntityTag=O] [Text=complains CharacterOffsetBegin=151 CharacterOffsetEnd=160 PartOfSpeech=VBZ Lemma=complain NamedEntityTag=O] [Text=that CharacterOffsetBegin=161 CharacterOffsetEnd=165 PartOfSpeech=IN Lemma=that NamedEntityTag=O] [Text=a CharacterOffsetBegin=166 CharacterOffsetEnd=167 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=story CharacterOffsetBegin=168 CharacterOffsetEnd=173 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=of CharacterOffsetBegin=174 CharacterOffsetEnd=176 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=a CharacterOffsetBegin=177 CharacterOffsetEnd=178 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=good CharacterOffsetBegin=179 CharacterOffsetEnd=183 PartOfSpeech=JJ Lemma=good NamedEntityTag=O] [Text=time CharacterOffsetBegin=184 CharacterOffsetEnd=188 PartOfSpeech=NN Lemma=time NamedEntityTag=O] [Text=is CharacterOffsetBegin=189 CharacterOffsetEnd=191 PartOfSpeech=VBZ Lemma=be NamedEntityTag=O] [Text=always CharacterOffsetBegin=192 CharacterOffsetEnd=198 PartOfSpeech=RB Lemma=always NamedEntityTag=O] [Text=too CharacterOffsetBegin=199 CharacterOffsetEnd=202 PartOfSpeech=RB Lemma=too NamedEntityTag=O] [Text=quickly CharacterOffsetBegin=203 CharacterOffsetEnd=210 PartOfSpeech=RB Lemma=quickly NamedEntityTag=O] [Text=told CharacterOffsetBegin=211 CharacterOffsetEnd=215 PartOfSpeech=VBD Lemma=tell NamedEntityTag=O] [Text=, CharacterOffsetBegin=215 CharacterOffsetEnd=216 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=but CharacterOffsetBegin=217 CharacterOffsetEnd=220 PartOfSpeech=CC Lemma=but NamedEntityTag=O] [Text=a CharacterOffsetBegin=221 CharacterOffsetEnd=222 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=story CharacterOffsetBegin=223 CharacterOffsetEnd=228 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=of CharacterOffsetBegin=229 CharacterOffsetEnd=231 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=evil CharacterOffsetBegin=232 CharacterOffsetEnd=236 PartOfSpeech=JJ Lemma=evil NamedEntityTag=O] [Text=times CharacterOffsetBegin=237 CharacterOffsetEnd=242 PartOfSpeech=NNS Lemma=time NamedEntityTag=O] [Text=often CharacterOffsetBegin=243 CharacterOffsetEnd=248 PartOfSpeech=RB Lemma=often NamedEntityTag=O] [Text=requires CharacterOffsetBegin=249 CharacterOffsetEnd=257 PartOfSpeech=VBZ Lemma=require NamedEntityTag=O] [Text=a CharacterOffsetBegin=258 CharacterOffsetEnd=259 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=great CharacterOffsetBegin=260 CharacterOffsetEnd=265 PartOfSpeech=JJ Lemma=great NamedEntityTag=O] [Text=many CharacterOffsetBegin=266 CharacterOffsetEnd=270 PartOfSpeech=JJ Lemma=many NamedEntityTag=O] [Text=words CharacterOffsetBegin=271 CharacterOffsetEnd=276 PartOfSpeech=NNS Lemma=word NamedEntityTag=O] [Text=to CharacterOffsetBegin=277 CharacterOffsetEnd=279 PartOfSpeech=TO Lemma=to NamedEntityTag=O] [Text=cover CharacterOffsetBegin=280 CharacterOffsetEnd=285 PartOfSpeech=VB Lemma=cover NamedEntityTag=O] [Text=the CharacterOffsetBegin=286 CharacterOffsetEnd=289 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=events CharacterOffsetBegin=290 CharacterOffsetEnd=296 PartOfSpeech=NNS Lemma=event NamedEntityTag=O] [Text=thereof.How CharacterOffsetBegin=297 CharacterOffsetEnd=308 PartOfSpeech=NN Lemma=thereof.how NamedEntityTag=O] [Text=often CharacterOffsetBegin=309 CharacterOffsetEnd=314 PartOfSpeech=RB Lemma=often NamedEntityTag=O] [Text=has CharacterOffsetBegin=315 CharacterOffsetEnd=318 PartOfSpeech=VBZ Lemma=have NamedEntityTag=O] [Text=that CharacterOffsetBegin=319 CharacterOffsetEnd=323 PartOfSpeech=IN Lemma=that NamedEntityTag=O] [Text=idea CharacterOffsetBegin=324 CharacterOffsetEnd=328 PartOfSpeech=NN Lemma=idea NamedEntityTag=O] [Text=fascinated CharacterOffsetBegin=329 CharacterOffsetEnd=339 PartOfSpeech=VBN Lemma=fascinate NamedEntityTag=O] [Text=me.Consider CharacterOffsetBegin=340 CharacterOffsetEnd=351 PartOfSpeech=NN Lemma=me.consider NamedEntityTag=O] [Text=also CharacterOffsetBegin=352 CharacterOffsetEnd=356 PartOfSpeech=RB Lemma=also NamedEntityTag=O] [Text=how CharacterOffsetBegin=357 CharacterOffsetEnd=360 PartOfSpeech=WRB Lemma=how NamedEntityTag=O] [Text=the CharacterOffsetBegin=361 CharacterOffsetEnd=364 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=story CharacterOffsetBegin=365 CharacterOffsetEnd=370 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=opens CharacterOffsetBegin=371 CharacterOffsetEnd=376 PartOfSpeech=VBZ Lemma=open NamedEntityTag=O] [Text=, CharacterOffsetBegin=376 CharacterOffsetEnd=377 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=with CharacterOffsetBegin=378 CharacterOffsetEnd=382 PartOfSpeech=IN Lemma=with NamedEntityTag=O] [Text=Bilbo CharacterOffsetBegin=383 CharacterOffsetEnd=388 PartOfSpeech=NNP Lemma=Bilbo NamedEntityTag=PERSON] [Text=\\'s CharacterOffsetBegin=388 CharacterOffsetEnd=390 PartOfSpeech=POS Lemma=\\'s NamedEntityTag=O] [Text=breezy CharacterOffsetBegin=391 CharacterOffsetEnd=397 PartOfSpeech=JJ Lemma=breezy NamedEntityTag=O] [Text=unreflective CharacterOffsetBegin=398 CharacterOffsetEnd=410 PartOfSpeech=JJ Lemma=unreflective NamedEntityTag=O] [Text=manners CharacterOffsetBegin=411 CharacterOffsetEnd=418 PartOfSpeech=NNS Lemma=manners NamedEntityTag=O] [Text=which CharacterOffsetBegin=419 CharacterOffsetEnd=424 PartOfSpeech=WDT Lemma=which NamedEntityTag=O] [Text=are CharacterOffsetBegin=425 CharacterOffsetEnd=428 PartOfSpeech=VBP Lemma=be NamedEntityTag=O] [Text=polite CharacterOffsetBegin=429 CharacterOffsetEnd=435 PartOfSpeech=JJ Lemma=polite NamedEntityTag=O] [Text=in CharacterOffsetBegin=436 CharacterOffsetEnd=438 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=form CharacterOffsetBegin=439 CharacterOffsetEnd=443 PartOfSpeech=NN Lemma=form NamedEntityTag=O] [Text=but CharacterOffsetBegin=444 CharacterOffsetEnd=447 PartOfSpeech=CC Lemma=but NamedEntityTag=O] [Text=not CharacterOffsetBegin=448 CharacterOffsetEnd=451 PartOfSpeech=RB Lemma=not NamedEntityTag=O] [Text=in CharacterOffsetBegin=452 CharacterOffsetEnd=454 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=spirit CharacterOffsetBegin=455 CharacterOffsetEnd=461 PartOfSpeech=NN Lemma=spirit NamedEntityTag=O] [Text=, CharacterOffsetBegin=461 CharacterOffsetEnd=462 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=and CharacterOffsetBegin=463 CharacterOffsetEnd=466 PartOfSpeech=CC Lemma=and NamedEntityTag=O] [Text=Gandalf CharacterOffsetBegin=467 CharacterOffsetEnd=474 PartOfSpeech=NNP Lemma=Gandalf NamedEntityTag=ORGANIZATION] [Text=\\'s CharacterOffsetBegin=474 CharacterOffsetEnd=476 PartOfSpeech=POS Lemma=\\'s NamedEntityTag=O] [Text=continual CharacterOffsetBegin=477 CharacterOffsetEnd=486 PartOfSpeech=JJ Lemma=continual NamedEntityTag=O] [Text=meditation CharacterOffsetBegin=487 CharacterOffsetEnd=497 PartOfSpeech=NN Lemma=meditation NamedEntityTag=O] [Text=on CharacterOffsetBegin=498 CharacterOffsetEnd=500 PartOfSpeech=IN Lemma=on NamedEntityTag=O] [Text=the CharacterOffsetBegin=501 CharacterOffsetEnd=504 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=meaning CharacterOffsetBegin=505 CharacterOffsetEnd=512 PartOfSpeech=NN Lemma=meaning NamedEntityTag=O] [Text=of CharacterOffsetBegin=513 CharacterOffsetEnd=515 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=` CharacterOffsetBegin=516 CharacterOffsetEnd=517 PartOfSpeech=`` Lemma=` NamedEntityTag=O] [Text=Good CharacterOffsetBegin=517 CharacterOffsetEnd=521 PartOfSpeech=JJ Lemma=good NamedEntityTag=O] [Text=morning CharacterOffsetBegin=522 CharacterOffsetEnd=529 PartOfSpeech=NN Lemma=morning NamedEntityTag=O] [Text=. CharacterOffsetBegin=529 CharacterOffsetEnd=530 PartOfSpeech=. Lemma=. NamedEntityTag=O] (ROOT (S (S (PP (IN At) (NP (PRP$ its) (NN heart))) (, ,) (NP (NP (DT the) (NN complaint)) (SBAR (S (NP (PRP I)) (VP (VBD opened) (NP (DT the) (NN review)) (SBAR (IN with) (S (VP (VBZ is) (ADVP (RB just)) (NP (NP (DT a) (NN variation)) (PP (IN on) (NP (CD one))) (PP (IN of) (NP (DT the) (JJ many) (JJ nuanced) (NNS observations)))))))))) (SBAR (S (NP (NNP Tolkien)) (VP (VBZ makes) (PP (IN in) (`` `) (NP (NP (DT The) (NP (NNP Hobbit) (POS \\'))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBZ complains) (SBAR (IN that) (S (NP (NP (DT a) (NN story)) (PP (IN of) (NP (DT a) (JJ good) (NN time)))) (VP (VBZ is) (ADVP (RB always)) (ADVP (RB too) (RB quickly)))))))))))))) (VP (VBD told))) (, ,) (CC but) (S (NP (NP (DT a) (NN story)) (PP (IN of) (NP (JJ evil) (NNS times)))) (ADVP (RB often)) (VP (VBZ requires) (S (NP (DT a) (JJ great) (JJ many) (NNS words)) (VP (TO to) (VP (VB cover) (NP (NP (DT the) (NNS events)) (SBAR (S (NP (NN thereof.How)) (ADVP (RB often)) (VP (VBZ has) (PP (IN that) (NP (NN idea))) (VP (VBN fascinated) (NP (NN me.Consider)) (ADVP (RB also)) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN story)) (VP (VBZ opens) (, ,) (PP (IN with) (NP (NP (NP (NNP Bilbo) (POS \\'s)) (JJ breezy) (JJ unreflective) (NNS manners)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (JJ polite) (PP (IN in) (NP (NN form)))) (PP (CONJP (CC but) (RB not)) (PP (IN in) (NP (NN spirit))) (, ,) (CC and) (PP (NP (NP (NNP Gandalf) (POS \\'s)) (JJ continual) (NN meditation)) (IN on) (NP (NP (DT the) (NN meaning)) (PP (IN of)))))))))))))))))) (`` `) (INTJ (JJ Good) (NN morning))))))) (. .)))\", \"text\": \"At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in \\'The Hobbit\\' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.How often has that idea fascinated me.Consider also how the story opens, with Bilbo\\'s breezy unreflective manners which are polite in form but not in spirit, and Gandalf\\'s continual meditation on the meaning of \\'Good morning.\", \"dependencies\": [[\"root\", \"ROOT\", \"told\"], [\"case\", \"heart\", \"At\"], [\"nmod:poss\", \"heart\", \"its\"], [\"nmod:at\", \"told\", \"heart\"], [\"punct\", \"told\", \",\"], [\"det\", \"complaint\", \"the\"], [\"mark\", \"is\", \"complaint\"], [\"nsubj\", \"told\", \"complaint\"], [\"nsubj\", \"opened\", \"I\"], [\"acl:relcl\", \"complaint\", \"opened\"], [\"det\", \"review\", \"the\"], [\"dobj\", \"opened\", \"review\"], [\"mark\", \"variation\", \"with\"], [\"cop\", \"variation\", \"is\"], [\"advmod\", \"variation\", \"just\"], [\"det\", \"variation\", \"a\"], [\"advcl:with\", \"opened\", \"variation\"], [\"case\", \"one\", \"on\"], [\"nmod:on\", \"variation\", \"one\"], [\"case\", \"observations\", \"of\"], [\"det\", \"observations\", \"the\"], [\"amod\", \"observations\", \"many\"], [\"amod\", \"observations\", \"nuanced\"], [\"nmod:of\", \"variation\", \"observations\"], [\"nsubj\", \"makes\", \"Tolkien\"], [\"acl:relcl\", \"complaint\", \"makes\"], [\"case\", \"Hobbit\", \"in\"], [\"punct\", \"Hobbit\", \"`\"], [\"det\", \"Hobbit\", \"The\"], [\"nmod:\\'\", \"makes\", \"Hobbit\"], [\"mark\", \"is\", \"Hobbit\"], [\"case\", \"Hobbit\", \"\\'\"], [\"advmod\", \"complains\", \"when\"], [\"nsubj\", \"complains\", \"he\"], [\"acl:relcl\", \"Hobbit\", \"complains\"], [\"ref\", \"complaint\", \"that\"], [\"ref\", \"Hobbit\", \"that\"], [\"det\", \"story\", \"a\"], [\"nsubj\", \"is\", \"story\"], [\"case\", \"time\", \"of\"], [\"det\", \"time\", \"a\"], [\"amod\", \"time\", \"good\"], [\"nmod:of\", \"story\", \"time\"], [\"ccomp\", \"complains\", \"is\"], [\"advmod\", \"is\", \"always\"], [\"advmod\", \"quickly\", \"too\"], [\"advmod\", \"is\", \"quickly\"], [\"punct\", \"told\", \",\"], [\"cc\", \"told\", \"but\"], [\"det\", \"story\", \"a\"], [\"nsubj\", \"requires\", \"story\"], [\"case\", \"times\", \"of\"], [\"amod\", \"times\", \"evil\"], [\"nmod:of\", \"story\", \"times\"], [\"advmod\", \"requires\", \"often\"], [\"conj:but\", \"told\", \"requires\"], [\"det\", \"words\", \"a\"], [\"amod\", \"words\", \"great\"], [\"amod\", \"words\", \"many\"], [\"dobj\", \"requires\", \"words\"], [\"nsubj:xsubj\", \"cover\", \"words\"], [\"mark\", \"cover\", \"to\"], [\"xcomp\", \"requires\", \"cover\"], [\"det\", \"events\", \"the\"], [\"dobj\", \"cover\", \"events\"], [\"case\", \"idea\", \"events\"], [\"nsubj\", \"fascinated\", \"thereof.How\"], [\"advmod\", \"fascinated\", \"often\"], [\"aux\", \"fascinated\", \"has\"], [\"ref\", \"events\", \"that\"], [\"nmod:that\", \"fascinated\", \"idea\"], [\"acl:relcl\", \"events\", \"fascinated\"], [\"dobj\", \"fascinated\", \"me.Consider\"], [\"advmod\", \"fascinated\", \"also\"], [\"advmod\", \"opens\", \"how\"], [\"det\", \"story\", \"the\"], [\"nsubj\", \"opens\", \"story\"], [\"dep\", \"fascinated\", \"opens\"], [\"punct\", \"opens\", \",\"], [\"case\", \"manners\", \"with\"], [\"nmod:poss\", \"manners\", \"Bilbo\"], [\"case\", \"Bilbo\", \"\\'s\"], [\"amod\", \"manners\", \"breezy\"], [\"amod\", \"manners\", \"unreflective\"], [\"nmod:with\", \"opens\", \"manners\"], [\"nsubj\", \"polite\", \"manners\"], [\"nsubj\", \"polite\", \"manners\"], [\"nsubj\", \"polite\", \"manners\"], [\"ref\", \"manners\", \"which\"], [\"cop\", \"polite\", \"are\"], [\"acl:relcl\", \"manners\", \"polite\"], [\"acl:relcl\", \"manners\", \"polite\"], [\"conj:negcc\", \"polite\", \"polite\"], [\"acl:relcl\", \"manners\", \"polite\"], [\"conj:and\", \"polite\", \"polite\"], [\"case\", \"form\", \"in\"], [\"nmod:in\", \"polite\", \"form\"], [\"cc\", \"not\", \"but\"], [\"cc\", \"polite\", \"not\"], [\"case\", \"spirit\", \"in\"], [\"nmod:in\", \"polite\", \"spirit\"], [\"punct\", \"spirit\", \",\"], [\"cc\", \"polite\", \"and\"], [\"nmod:poss\", \"meditation\", \"Gandalf\"], [\"case\", \"Gandalf\", \"\\'s\"], [\"amod\", \"meditation\", \"continual\"], [\"nmod:on\", \"polite\", \"meditation\"], [\"case\", \"meditation\", \"on\"], [\"det\", \"meaning\", \"the\"], [\"dep\", \"meditation\", \"meaning\"], [\"acl\", \"meaning\", \"of\"], [\"punct\", \"cover\", \"`\"], [\"amod\", \"morning\", \"Good\"], [\"discourse\", \"cover\", \"morning\"], [\"punct\", \"told\", \".\"]], \"words\": [[\"At\", {\"NamedEntityTag\": \"O\", \"CharacterOffsetEnd\": \"2\", \"Lemma\": \"at\", \"PartOfSpeech\": \"IN\", \"CharacterOffsetBegin\": \"0\"}]]}]}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corenlp.parse(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict = loads(server.parse(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'coref': [[[[u'the story', 0, 1, 70, 72],\n",
       "    [u'a story of a good time', 0, 4, 33, 39]]]],\n",
       " u'sentences': [{u'dependencies': [[u'root', u'ROOT', u'told'],\n",
       "    [u'case', u'heart', u'At'],\n",
       "    [u'nmod:poss', u'heart', u'its'],\n",
       "    [u'nmod:at', u'told', u'heart'],\n",
       "    [u'punct', u'told', u','],\n",
       "    [u'det', u'complaint', u'the'],\n",
       "    [u'mark', u'is', u'complaint'],\n",
       "    [u'nsubj', u'told', u'complaint'],\n",
       "    [u'nsubj', u'opened', u'I'],\n",
       "    [u'acl:relcl', u'complaint', u'opened'],\n",
       "    [u'det', u'review', u'the'],\n",
       "    [u'dobj', u'opened', u'review'],\n",
       "    [u'mark', u'variation', u'with'],\n",
       "    [u'cop', u'variation', u'is'],\n",
       "    [u'advmod', u'variation', u'just'],\n",
       "    [u'det', u'variation', u'a'],\n",
       "    [u'advcl:with', u'opened', u'variation'],\n",
       "    [u'case', u'one', u'on'],\n",
       "    [u'nmod:on', u'variation', u'one'],\n",
       "    [u'case', u'observations', u'of'],\n",
       "    [u'det', u'observations', u'the'],\n",
       "    [u'amod', u'observations', u'many'],\n",
       "    [u'amod', u'observations', u'nuanced'],\n",
       "    [u'nmod:of', u'variation', u'observations'],\n",
       "    [u'nsubj', u'makes', u'Tolkien'],\n",
       "    [u'acl:relcl', u'complaint', u'makes'],\n",
       "    [u'case', u'Hobbit', u'in'],\n",
       "    [u'punct', u'Hobbit', u'`'],\n",
       "    [u'det', u'Hobbit', u'The'],\n",
       "    [u\"nmod:'\", u'makes', u'Hobbit'],\n",
       "    [u'mark', u'is', u'Hobbit'],\n",
       "    [u'case', u'Hobbit', u\"'\"],\n",
       "    [u'advmod', u'complains', u'when'],\n",
       "    [u'nsubj', u'complains', u'he'],\n",
       "    [u'acl:relcl', u'Hobbit', u'complains'],\n",
       "    [u'ref', u'complaint', u'that'],\n",
       "    [u'ref', u'Hobbit', u'that'],\n",
       "    [u'det', u'story', u'a'],\n",
       "    [u'nsubj', u'is', u'story'],\n",
       "    [u'case', u'time', u'of'],\n",
       "    [u'det', u'time', u'a'],\n",
       "    [u'amod', u'time', u'good'],\n",
       "    [u'nmod:of', u'story', u'time'],\n",
       "    [u'ccomp', u'complains', u'is'],\n",
       "    [u'advmod', u'is', u'always'],\n",
       "    [u'advmod', u'quickly', u'too'],\n",
       "    [u'advmod', u'is', u'quickly'],\n",
       "    [u'punct', u'told', u','],\n",
       "    [u'cc', u'told', u'but'],\n",
       "    [u'det', u'story', u'a'],\n",
       "    [u'nsubj', u'requires', u'story'],\n",
       "    [u'case', u'times', u'of'],\n",
       "    [u'amod', u'times', u'evil'],\n",
       "    [u'nmod:of', u'story', u'times'],\n",
       "    [u'advmod', u'requires', u'often'],\n",
       "    [u'conj:but', u'told', u'requires'],\n",
       "    [u'det', u'words', u'a'],\n",
       "    [u'amod', u'words', u'great'],\n",
       "    [u'amod', u'words', u'many'],\n",
       "    [u'dobj', u'requires', u'words'],\n",
       "    [u'nsubj:xsubj', u'cover', u'words'],\n",
       "    [u'mark', u'cover', u'to'],\n",
       "    [u'xcomp', u'requires', u'cover'],\n",
       "    [u'det', u'events', u'the'],\n",
       "    [u'dobj', u'cover', u'events'],\n",
       "    [u'case', u'idea', u'events'],\n",
       "    [u'nsubj', u'fascinated', u'thereof.How'],\n",
       "    [u'advmod', u'fascinated', u'often'],\n",
       "    [u'aux', u'fascinated', u'has'],\n",
       "    [u'ref', u'events', u'that'],\n",
       "    [u'nmod:that', u'fascinated', u'idea'],\n",
       "    [u'acl:relcl', u'events', u'fascinated'],\n",
       "    [u'dobj', u'fascinated', u'me.Consider'],\n",
       "    [u'advmod', u'fascinated', u'also'],\n",
       "    [u'advmod', u'opens', u'how'],\n",
       "    [u'det', u'story', u'the'],\n",
       "    [u'nsubj', u'opens', u'story'],\n",
       "    [u'dep', u'fascinated', u'opens'],\n",
       "    [u'punct', u'opens', u','],\n",
       "    [u'case', u'manners', u'with'],\n",
       "    [u'nmod:poss', u'manners', u'Bilbo'],\n",
       "    [u'case', u'Bilbo', u\"'s\"],\n",
       "    [u'amod', u'manners', u'breezy'],\n",
       "    [u'amod', u'manners', u'unreflective'],\n",
       "    [u'nmod:with', u'opens', u'manners'],\n",
       "    [u'nsubj', u'polite', u'manners'],\n",
       "    [u'nsubj', u'polite', u'manners'],\n",
       "    [u'nsubj', u'polite', u'manners'],\n",
       "    [u'ref', u'manners', u'which'],\n",
       "    [u'cop', u'polite', u'are'],\n",
       "    [u'acl:relcl', u'manners', u'polite'],\n",
       "    [u'acl:relcl', u'manners', u'polite'],\n",
       "    [u'conj:negcc', u'polite', u'polite'],\n",
       "    [u'acl:relcl', u'manners', u'polite'],\n",
       "    [u'conj:and', u'polite', u'polite'],\n",
       "    [u'case', u'form', u'in'],\n",
       "    [u'nmod:in', u'polite', u'form'],\n",
       "    [u'cc', u'not', u'but'],\n",
       "    [u'cc', u'polite', u'not'],\n",
       "    [u'case', u'spirit', u'in'],\n",
       "    [u'nmod:in', u'polite', u'spirit'],\n",
       "    [u'punct', u'spirit', u','],\n",
       "    [u'cc', u'polite', u'and'],\n",
       "    [u'nmod:poss', u'meditation', u'Gandalf'],\n",
       "    [u'case', u'Gandalf', u\"'s\"],\n",
       "    [u'amod', u'meditation', u'continual'],\n",
       "    [u'nmod:on', u'polite', u'meditation'],\n",
       "    [u'case', u'meditation', u'on'],\n",
       "    [u'det', u'meaning', u'the'],\n",
       "    [u'dep', u'meditation', u'meaning'],\n",
       "    [u'acl', u'meaning', u'of'],\n",
       "    [u'punct', u'cover', u'`'],\n",
       "    [u'amod', u'morning', u'Good'],\n",
       "    [u'discourse', u'cover', u'morning'],\n",
       "    [u'punct', u'told', u'.']],\n",
       "   u'parsetree': u\"[Text=its CharacterOffsetBegin=3 CharacterOffsetEnd=6 PartOfSpeech=PRP$ Lemma=its NamedEntityTag=O] [Text=heart CharacterOffsetBegin=7 CharacterOffsetEnd=12 PartOfSpeech=NN Lemma=heart NamedEntityTag=O] [Text=, CharacterOffsetBegin=12 CharacterOffsetEnd=13 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=the CharacterOffsetBegin=14 CharacterOffsetEnd=17 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=complaint CharacterOffsetBegin=18 CharacterOffsetEnd=27 PartOfSpeech=NN Lemma=complaint NamedEntityTag=O] [Text=I CharacterOffsetBegin=28 CharacterOffsetEnd=29 PartOfSpeech=PRP Lemma=I NamedEntityTag=O] [Text=opened CharacterOffsetBegin=30 CharacterOffsetEnd=36 PartOfSpeech=VBD Lemma=open NamedEntityTag=O] [Text=the CharacterOffsetBegin=37 CharacterOffsetEnd=40 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=review CharacterOffsetBegin=41 CharacterOffsetEnd=47 PartOfSpeech=NN Lemma=review NamedEntityTag=O] [Text=with CharacterOffsetBegin=48 CharacterOffsetEnd=52 PartOfSpeech=IN Lemma=with NamedEntityTag=O] [Text=is CharacterOffsetBegin=53 CharacterOffsetEnd=55 PartOfSpeech=VBZ Lemma=be NamedEntityTag=O] [Text=just CharacterOffsetBegin=56 CharacterOffsetEnd=60 PartOfSpeech=RB Lemma=just NamedEntityTag=O] [Text=a CharacterOffsetBegin=61 CharacterOffsetEnd=62 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=variation CharacterOffsetBegin=63 CharacterOffsetEnd=72 PartOfSpeech=NN Lemma=variation NamedEntityTag=O] [Text=on CharacterOffsetBegin=73 CharacterOffsetEnd=75 PartOfSpeech=IN Lemma=on NamedEntityTag=O] [Text=one CharacterOffsetBegin=76 CharacterOffsetEnd=79 PartOfSpeech=CD Lemma=one NamedEntityTag=NUMBER NormalizedNamedEntityTag=1.0] [Text=of CharacterOffsetBegin=80 CharacterOffsetEnd=82 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=the CharacterOffsetBegin=83 CharacterOffsetEnd=86 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=many CharacterOffsetBegin=87 CharacterOffsetEnd=91 PartOfSpeech=JJ Lemma=many NamedEntityTag=O] [Text=nuanced CharacterOffsetBegin=92 CharacterOffsetEnd=99 PartOfSpeech=JJ Lemma=nuanced NamedEntityTag=O] [Text=observations CharacterOffsetBegin=100 CharacterOffsetEnd=112 PartOfSpeech=NNS Lemma=observation NamedEntityTag=O] [Text=Tolkien CharacterOffsetBegin=113 CharacterOffsetEnd=120 PartOfSpeech=NNP Lemma=Tolkien NamedEntityTag=ORGANIZATION] [Text=makes CharacterOffsetBegin=121 CharacterOffsetEnd=126 PartOfSpeech=VBZ Lemma=make NamedEntityTag=O] [Text=in CharacterOffsetBegin=127 CharacterOffsetEnd=129 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=` CharacterOffsetBegin=130 CharacterOffsetEnd=131 PartOfSpeech=`` Lemma=` NamedEntityTag=O] [Text=The CharacterOffsetBegin=131 CharacterOffsetEnd=134 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=Hobbit CharacterOffsetBegin=135 CharacterOffsetEnd=141 PartOfSpeech=NNP Lemma=Hobbit NamedEntityTag=O] [Text=' CharacterOffsetBegin=141 CharacterOffsetEnd=142 PartOfSpeech=POS Lemma=' NamedEntityTag=O] [Text=when CharacterOffsetBegin=143 CharacterOffsetEnd=147 PartOfSpeech=WRB Lemma=when NamedEntityTag=O] [Text=he CharacterOffsetBegin=148 CharacterOffsetEnd=150 PartOfSpeech=PRP Lemma=he NamedEntityTag=O] [Text=complains CharacterOffsetBegin=151 CharacterOffsetEnd=160 PartOfSpeech=VBZ Lemma=complain NamedEntityTag=O] [Text=that CharacterOffsetBegin=161 CharacterOffsetEnd=165 PartOfSpeech=IN Lemma=that NamedEntityTag=O] [Text=a CharacterOffsetBegin=166 CharacterOffsetEnd=167 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=story CharacterOffsetBegin=168 CharacterOffsetEnd=173 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=of CharacterOffsetBegin=174 CharacterOffsetEnd=176 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=a CharacterOffsetBegin=177 CharacterOffsetEnd=178 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=good CharacterOffsetBegin=179 CharacterOffsetEnd=183 PartOfSpeech=JJ Lemma=good NamedEntityTag=O] [Text=time CharacterOffsetBegin=184 CharacterOffsetEnd=188 PartOfSpeech=NN Lemma=time NamedEntityTag=O] [Text=is CharacterOffsetBegin=189 CharacterOffsetEnd=191 PartOfSpeech=VBZ Lemma=be NamedEntityTag=O] [Text=always CharacterOffsetBegin=192 CharacterOffsetEnd=198 PartOfSpeech=RB Lemma=always NamedEntityTag=O] [Text=too CharacterOffsetBegin=199 CharacterOffsetEnd=202 PartOfSpeech=RB Lemma=too NamedEntityTag=O] [Text=quickly CharacterOffsetBegin=203 CharacterOffsetEnd=210 PartOfSpeech=RB Lemma=quickly NamedEntityTag=O] [Text=told CharacterOffsetBegin=211 CharacterOffsetEnd=215 PartOfSpeech=VBD Lemma=tell NamedEntityTag=O] [Text=, CharacterOffsetBegin=215 CharacterOffsetEnd=216 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=but CharacterOffsetBegin=217 CharacterOffsetEnd=220 PartOfSpeech=CC Lemma=but NamedEntityTag=O] [Text=a CharacterOffsetBegin=221 CharacterOffsetEnd=222 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=story CharacterOffsetBegin=223 CharacterOffsetEnd=228 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=of CharacterOffsetBegin=229 CharacterOffsetEnd=231 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=evil CharacterOffsetBegin=232 CharacterOffsetEnd=236 PartOfSpeech=JJ Lemma=evil NamedEntityTag=O] [Text=times CharacterOffsetBegin=237 CharacterOffsetEnd=242 PartOfSpeech=NNS Lemma=time NamedEntityTag=O] [Text=often CharacterOffsetBegin=243 CharacterOffsetEnd=248 PartOfSpeech=RB Lemma=often NamedEntityTag=O] [Text=requires CharacterOffsetBegin=249 CharacterOffsetEnd=257 PartOfSpeech=VBZ Lemma=require NamedEntityTag=O] [Text=a CharacterOffsetBegin=258 CharacterOffsetEnd=259 PartOfSpeech=DT Lemma=a NamedEntityTag=O] [Text=great CharacterOffsetBegin=260 CharacterOffsetEnd=265 PartOfSpeech=JJ Lemma=great NamedEntityTag=O] [Text=many CharacterOffsetBegin=266 CharacterOffsetEnd=270 PartOfSpeech=JJ Lemma=many NamedEntityTag=O] [Text=words CharacterOffsetBegin=271 CharacterOffsetEnd=276 PartOfSpeech=NNS Lemma=word NamedEntityTag=O] [Text=to CharacterOffsetBegin=277 CharacterOffsetEnd=279 PartOfSpeech=TO Lemma=to NamedEntityTag=O] [Text=cover CharacterOffsetBegin=280 CharacterOffsetEnd=285 PartOfSpeech=VB Lemma=cover NamedEntityTag=O] [Text=the CharacterOffsetBegin=286 CharacterOffsetEnd=289 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=events CharacterOffsetBegin=290 CharacterOffsetEnd=296 PartOfSpeech=NNS Lemma=event NamedEntityTag=O] [Text=thereof.How CharacterOffsetBegin=297 CharacterOffsetEnd=308 PartOfSpeech=NN Lemma=thereof.how NamedEntityTag=O] [Text=often CharacterOffsetBegin=309 CharacterOffsetEnd=314 PartOfSpeech=RB Lemma=often NamedEntityTag=O] [Text=has CharacterOffsetBegin=315 CharacterOffsetEnd=318 PartOfSpeech=VBZ Lemma=have NamedEntityTag=O] [Text=that CharacterOffsetBegin=319 CharacterOffsetEnd=323 PartOfSpeech=IN Lemma=that NamedEntityTag=O] [Text=idea CharacterOffsetBegin=324 CharacterOffsetEnd=328 PartOfSpeech=NN Lemma=idea NamedEntityTag=O] [Text=fascinated CharacterOffsetBegin=329 CharacterOffsetEnd=339 PartOfSpeech=VBN Lemma=fascinate NamedEntityTag=O] [Text=me.Consider CharacterOffsetBegin=340 CharacterOffsetEnd=351 PartOfSpeech=NN Lemma=me.consider NamedEntityTag=O] [Text=also CharacterOffsetBegin=352 CharacterOffsetEnd=356 PartOfSpeech=RB Lemma=also NamedEntityTag=O] [Text=how CharacterOffsetBegin=357 CharacterOffsetEnd=360 PartOfSpeech=WRB Lemma=how NamedEntityTag=O] [Text=the CharacterOffsetBegin=361 CharacterOffsetEnd=364 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=story CharacterOffsetBegin=365 CharacterOffsetEnd=370 PartOfSpeech=NN Lemma=story NamedEntityTag=O] [Text=opens CharacterOffsetBegin=371 CharacterOffsetEnd=376 PartOfSpeech=VBZ Lemma=open NamedEntityTag=O] [Text=, CharacterOffsetBegin=376 CharacterOffsetEnd=377 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=with CharacterOffsetBegin=378 CharacterOffsetEnd=382 PartOfSpeech=IN Lemma=with NamedEntityTag=O] [Text=Bilbo CharacterOffsetBegin=383 CharacterOffsetEnd=388 PartOfSpeech=NNP Lemma=Bilbo NamedEntityTag=PERSON] [Text='s CharacterOffsetBegin=388 CharacterOffsetEnd=390 PartOfSpeech=POS Lemma='s NamedEntityTag=O] [Text=breezy CharacterOffsetBegin=391 CharacterOffsetEnd=397 PartOfSpeech=JJ Lemma=breezy NamedEntityTag=O] [Text=unreflective CharacterOffsetBegin=398 CharacterOffsetEnd=410 PartOfSpeech=JJ Lemma=unreflective NamedEntityTag=O] [Text=manners CharacterOffsetBegin=411 CharacterOffsetEnd=418 PartOfSpeech=NNS Lemma=manners NamedEntityTag=O] [Text=which CharacterOffsetBegin=419 CharacterOffsetEnd=424 PartOfSpeech=WDT Lemma=which NamedEntityTag=O] [Text=are CharacterOffsetBegin=425 CharacterOffsetEnd=428 PartOfSpeech=VBP Lemma=be NamedEntityTag=O] [Text=polite CharacterOffsetBegin=429 CharacterOffsetEnd=435 PartOfSpeech=JJ Lemma=polite NamedEntityTag=O] [Text=in CharacterOffsetBegin=436 CharacterOffsetEnd=438 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=form CharacterOffsetBegin=439 CharacterOffsetEnd=443 PartOfSpeech=NN Lemma=form NamedEntityTag=O] [Text=but CharacterOffsetBegin=444 CharacterOffsetEnd=447 PartOfSpeech=CC Lemma=but NamedEntityTag=O] [Text=not CharacterOffsetBegin=448 CharacterOffsetEnd=451 PartOfSpeech=RB Lemma=not NamedEntityTag=O] [Text=in CharacterOffsetBegin=452 CharacterOffsetEnd=454 PartOfSpeech=IN Lemma=in NamedEntityTag=O] [Text=spirit CharacterOffsetBegin=455 CharacterOffsetEnd=461 PartOfSpeech=NN Lemma=spirit NamedEntityTag=O] [Text=, CharacterOffsetBegin=461 CharacterOffsetEnd=462 PartOfSpeech=, Lemma=, NamedEntityTag=O] [Text=and CharacterOffsetBegin=463 CharacterOffsetEnd=466 PartOfSpeech=CC Lemma=and NamedEntityTag=O] [Text=Gandalf CharacterOffsetBegin=467 CharacterOffsetEnd=474 PartOfSpeech=NNP Lemma=Gandalf NamedEntityTag=ORGANIZATION] [Text='s CharacterOffsetBegin=474 CharacterOffsetEnd=476 PartOfSpeech=POS Lemma='s NamedEntityTag=O] [Text=continual CharacterOffsetBegin=477 CharacterOffsetEnd=486 PartOfSpeech=JJ Lemma=continual NamedEntityTag=O] [Text=meditation CharacterOffsetBegin=487 CharacterOffsetEnd=497 PartOfSpeech=NN Lemma=meditation NamedEntityTag=O] [Text=on CharacterOffsetBegin=498 CharacterOffsetEnd=500 PartOfSpeech=IN Lemma=on NamedEntityTag=O] [Text=the CharacterOffsetBegin=501 CharacterOffsetEnd=504 PartOfSpeech=DT Lemma=the NamedEntityTag=O] [Text=meaning CharacterOffsetBegin=505 CharacterOffsetEnd=512 PartOfSpeech=NN Lemma=meaning NamedEntityTag=O] [Text=of CharacterOffsetBegin=513 CharacterOffsetEnd=515 PartOfSpeech=IN Lemma=of NamedEntityTag=O] [Text=` CharacterOffsetBegin=516 CharacterOffsetEnd=517 PartOfSpeech=`` Lemma=` NamedEntityTag=O] [Text=Good CharacterOffsetBegin=517 CharacterOffsetEnd=521 PartOfSpeech=JJ Lemma=good NamedEntityTag=O] [Text=morning CharacterOffsetBegin=522 CharacterOffsetEnd=529 PartOfSpeech=NN Lemma=morning NamedEntityTag=O] [Text=. CharacterOffsetBegin=529 CharacterOffsetEnd=530 PartOfSpeech=. Lemma=. NamedEntityTag=O] (ROOT (S (S (PP (IN At) (NP (PRP$ its) (NN heart))) (, ,) (NP (NP (DT the) (NN complaint)) (SBAR (S (NP (PRP I)) (VP (VBD opened) (NP (DT the) (NN review)) (SBAR (IN with) (S (VP (VBZ is) (ADVP (RB just)) (NP (NP (DT a) (NN variation)) (PP (IN on) (NP (CD one))) (PP (IN of) (NP (DT the) (JJ many) (JJ nuanced) (NNS observations)))))))))) (SBAR (S (NP (NNP Tolkien)) (VP (VBZ makes) (PP (IN in) (`` `) (NP (NP (DT The) (NP (NNP Hobbit) (POS '))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBZ complains) (SBAR (IN that) (S (NP (NP (DT a) (NN story)) (PP (IN of) (NP (DT a) (JJ good) (NN time)))) (VP (VBZ is) (ADVP (RB always)) (ADVP (RB too) (RB quickly)))))))))))))) (VP (VBD told))) (, ,) (CC but) (S (NP (NP (DT a) (NN story)) (PP (IN of) (NP (JJ evil) (NNS times)))) (ADVP (RB often)) (VP (VBZ requires) (S (NP (DT a) (JJ great) (JJ many) (NNS words)) (VP (TO to) (VP (VB cover) (NP (NP (DT the) (NNS events)) (SBAR (S (NP (NN thereof.How)) (ADVP (RB often)) (VP (VBZ has) (PP (IN that) (NP (NN idea))) (VP (VBN fascinated) (NP (NN me.Consider)) (ADVP (RB also)) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN story)) (VP (VBZ opens) (, ,) (PP (IN with) (NP (NP (NP (NNP Bilbo) (POS 's)) (JJ breezy) (JJ unreflective) (NNS manners)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (JJ polite) (PP (IN in) (NP (NN form)))) (PP (CONJP (CC but) (RB not)) (PP (IN in) (NP (NN spirit))) (, ,) (CC and) (PP (NP (NP (NNP Gandalf) (POS 's)) (JJ continual) (NN meditation)) (IN on) (NP (NP (DT the) (NN meaning)) (PP (IN of)))))))))))))))))) (`` `) (INTJ (JJ Good) (NN morning))))))) (. .)))\",\n",
       "   u'text': u\"At its heart, the complaint I opened the review with is just a variation on one of the many nuanced observations Tolkien makes in 'The Hobbit' when he complains that a story of a good time is always too quickly told, but a story of evil times often requires a great many words to cover the events thereof.How often has that idea fascinated me.Consider also how the story opens, with Bilbo's breezy unreflective manners which are polite in form but not in spirit, and Gandalf's continual meditation on the meaning of 'Good morning.\",\n",
       "   u'words': [[u'At',\n",
       "     {u'CharacterOffsetBegin': u'0',\n",
       "      u'CharacterOffsetEnd': u'2',\n",
       "      u'Lemma': u'at',\n",
       "      u'NamedEntityTag': u'O',\n",
       "      u'PartOfSpeech': u'IN'}]]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sentences = sent_tokenize(texts[0])\n",
    "total_sentences = len(t_sentences)\n",
    "total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
