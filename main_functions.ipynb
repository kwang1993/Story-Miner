{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_node_attributes(n, annotation):\n",
    "    '''\n",
    "    This function takes a node and \n",
    "    '''\n",
    "    # ROOT does not appear in the tree\n",
    "    n_att = {}\n",
    "    if n == \"ROOT-0\":\n",
    "        n_word = \"ROOT\"\n",
    "        n_att[\"word\"] = n_word\n",
    "        n_att[\"id\"] = n\n",
    "        return n_att\n",
    "    \n",
    "    # extract attributes\n",
    "    n_splitted = n.split('-')\n",
    "    n_word, n_ind = n.split('-')[0], n.split('-')[1]\n",
    "    try:\n",
    "        n_ind = int(n_ind) - 1 # make it 0 base - ROOT becomes \"-1\"\n",
    "    except:\n",
    "        print \"Tokenizer failed during parsing, Ex. there might be a dash in the sentence!\"\n",
    "        return None\n",
    "    n_pos = annotation['pos'][n_ind][1]\n",
    "    \n",
    "    n_att[\"word\"] = n_word\n",
    "    n_att[\"ind\"] = n_ind\n",
    "    n_att[\"pos\"] = n_pos\n",
    "    n_att[\"id\"] = n\n",
    "    \n",
    "    return n_att\n",
    "        \n",
    "def create_dep_graph(annotation):\n",
    "    dep_parse = annotation['dep_parse']\n",
    "    if dep_parse == '':\n",
    "        return None\n",
    "    dp_list = dep_parse.split('\\n')\n",
    "    #print dp_list\n",
    "    pattern = re.compile(r'.+?\\((.+?), (.+?)\\)')    \n",
    "    #g = nx.Graph()\n",
    "    g_dir = nx.DiGraph()\n",
    "    for dep in dp_list:\n",
    "        m = pattern.search(dep)\n",
    "        n1 = m.group(1)#.split('-')[0]\n",
    "        n2 = m.group(2)#.split('-')[0]\n",
    "        n1_att = create_node_attributes(n1, annotation)\n",
    "        n2_att = create_node_attributes(n2, annotation)\n",
    "        if n1_att is None or n2_att is None:\n",
    "            return None\n",
    "        g_dir.add_node(n1, n1_att)\n",
    "        g_dir.add_node(n2, n2_att)\n",
    "        e_rel = dep[:dep.find(\"(\")]\n",
    "        #edges.append(e)\n",
    "        g_dir.add_edge(n1, n2, {'rel' : e_rel}, label = e_rel)\n",
    "    return g_dir\n",
    "\n",
    "def get_simp_rel(rel, option = \"SVO\"):\n",
    "    # add options later\n",
    "    '''\n",
    "    Lower case, Strip\n",
    "    '''\n",
    "    arg1 = rel['arg1'].lower().strip()\n",
    "    arg2 = rel['arg2'].lower().strip()\n",
    "    r = rel['rel'].lower().strip()\n",
    "\n",
    "    '''\n",
    "    Mapping:\n",
    "    (I,You,We -> Parents)\n",
    "    '''    \n",
    "    parent_list = [\"i\",\"you\",\"we\",\"your\",\"us\",\"they\"]\n",
    "    if arg1 in parent_list:\n",
    "        arg1 = \"parent\"\n",
    "    if arg2 in parent_list:\n",
    "        arg2 = \"parent\"\n",
    "        \n",
    "    child_list = [\"children\",\"kid\",\"kids\",\"child\",\"son\",\"daughter\"]\n",
    "    if arg1 in child_list:\n",
    "        arg1 = \"child\"\n",
    "    if arg2 in child_list:\n",
    "        arg2 = \"child\"    \n",
    "    '''\n",
    "    Stemming\n",
    "    '''\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    arg1 = stemmer.stem(arg1) \n",
    "    arg2 = stemmer.stem(arg2)\n",
    "    r = stemmer.stem(r)\n",
    "    \n",
    "    rel_simp = rel\n",
    "    rel_simp['arg1'] = arg1\n",
    "    rel_simp['arg2'] = arg2\n",
    "    rel_simp['rel'] = r\n",
    "    return rel_simp\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_relations(g_dir, annotation, option=\"SVO\"):\n",
    "    relations = []\n",
    "    '''\n",
    "    Simplified relations:\n",
    "    meaning that we only keep head words, do stemming, map words to their actual actor ( I,we,you -> parents)\n",
    "    '''\n",
    "    relations_simp = [] \n",
    "    if option == \"SVO\":\n",
    "        t_verbs = annotation['verbs']\n",
    "        for v in t_verbs:\n",
    "            v_id = v+\"-\"+str(annotation['words'].index(v)+1) \n",
    "            try:\n",
    "                g_dir_v = g_dir[v_id] #adjacency of v_id\n",
    "            except:\n",
    "                print v_id, \" does not appeared as a separate node in parsing tree.\"\n",
    "                continue\n",
    "            nsubj_list = []\n",
    "            dobj_list = []\n",
    "            for word_id, e in g_dir_v.iteritems():\n",
    "                if e[\"rel\"] == \"nsubj\":\n",
    "                    nsubj_list.append(word_id)\n",
    "                if e[\"rel\"] == \"dobj\":\n",
    "                    dobj_list.append(word_id)\n",
    "            if len(nsubj_list) > 0 and len(dobj_list) > 0:\n",
    "                for s in nsubj_list:\n",
    "                    for o in dobj_list:\n",
    "                        rel = {}\n",
    "                        rel[\"rel\"] = v\n",
    "                        rel[\"arg1\"] = s.split(\"-\")[0]\n",
    "                        rel[\"arg2\"] = o.split(\"-\")[0]\n",
    "                        rel[\"pattern\"] = \"(nsubj, verb, dobj)\"\n",
    "                        relations.append(rel)\n",
    "                        rel_simp = get_simp_rel(rel,option)\n",
    "                        relations_simp.append(rel_simp)\n",
    "    return relations, relations_simp\n",
    "\n",
    "def create_argument_graph(df, source, target, edge_attr=None, graph_type=\"directed\"):\n",
    "    ''' Return a graph from Pandas DataFrame.\n",
    "    Modified version of \"from_pandas_dataframe\" function.\n",
    "    '''\n",
    "    if graph_type == \"undirected\":\n",
    "        g = nx.Graph()\n",
    "    elif graph_type == \"directed\":\n",
    "        g = nx.DiGraph()\n",
    "    else:\n",
    "        g = nx.MultiGraph()\n",
    "    \n",
    "    src_i = df.columns.get_loc(source)\n",
    "    tar_i = df.columns.get_loc(target)\n",
    "    label_i = df.columns.get_loc(edge_attr)\n",
    "    if edge_attr:\n",
    "        # If all additional columns requested, build up a list of tuples\n",
    "        # [(name, index),...]\n",
    "        if edge_attr is True:\n",
    "            # Create a list of all columns indices, ignore nodes\n",
    "            edge_i = []\n",
    "            for i, col in enumerate(df.columns):\n",
    "                if col is not source and col is not target:\n",
    "                    edge_i.append((col, i))\n",
    "        # If a list or tuple of name is requested\n",
    "        elif isinstance(edge_attr, (list, tuple)):\n",
    "            edge_i = [(i, df.columns.get_loc(i)) for i in edge_attr]\n",
    "        # If a string or int is passed\n",
    "        else:\n",
    "            edge_i = [(edge_attr, df.columns.get_loc(edge_attr)),]\n",
    "\n",
    "        # Iteration on values returns the rows as Numpy arrays\n",
    "        for row in df.values:\n",
    "            g.add_edge(row[src_i], row[tar_i], label = row[label_i])#{i:row[j] for i, j in edge_i},label=row[label_i])\n",
    "    \n",
    "    # If no column names are given, then just return the edges.\n",
    "    else:\n",
    "        for row in df.values:\n",
    "            g.add_edge(row[src_i], row[tar_i])\n",
    "\n",
    "    return g\n",
    "\n",
    "def create_argument_multiGraph(df, source, target):\n",
    "    g = nx.MultiGraph()\n",
    "    print df\n",
    "    nodes = set()\n",
    "    nodes = list(nodes.union(df[source],df[target]))\n",
    "    for n in nodes:\n",
    "        g.add_node(n)\n",
    "        ''' Get dataframe in which n is the source'''\n",
    "        df_n = df[df[source] == n]\n",
    "        \n",
    "        g.add_edge(n,)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
